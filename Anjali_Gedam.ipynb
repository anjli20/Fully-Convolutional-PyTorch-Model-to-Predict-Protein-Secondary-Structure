{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68978,"databundleVersionId":7709659,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"DEEP LEARNING COURSEWORK\nNAME- ANJALI GEDAM\nGUID- 2925297G","metadata":{}},{"cell_type":"markdown","source":"IMPORT LIBRARIES","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport numpy as np\nimport os\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-18T15:26:55.483400Z","iopub.execute_input":"2024-03-18T15:26:55.484361Z","iopub.status.idle":"2024-03-18T15:26:57.882708Z","shell.execute_reply.started":"2024-03-18T15:26:55.484323Z","shell.execute_reply":"2024-03-18T15:26:57.881489Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"FILES PATH","metadata":{}},{"cell_type":"code","source":"seqs_train_path = '/kaggle/input/deep-learning-for-msc-202324/seqs_train.csv'\nlabels_train_path = '/kaggle/input/deep-learning-for-msc-202324/labels_train.csv'\ntrain_path = '/kaggle/input/deep-learning-for-msc-202324/train'\nseqs_test_path = '/kaggle/input/deep-learning-for-msc-202324/seqs_test.csv'\ntest_path = '/kaggle/input/deep-learning-for-msc-202324/test'","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.884837Z","iopub.execute_input":"2024-03-18T15:26:57.885330Z","iopub.status.idle":"2024-03-18T15:26:57.891920Z","shell.execute_reply.started":"2024-03-18T15:26:57.885299Z","shell.execute_reply":"2024-03-18T15:26:57.890808Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"MAPPING","metadata":{}},{"cell_type":"code","source":"amino_acid_mapping = {\n    'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9,\n    'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19,\n    'X': 20, 'B': 21, 'Z': 22, 'J': 23, '-': 24\n}\n\nsec_struct_mapping = {'H': 0, 'E': 1, 'C': 2}  ","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.893316Z","iopub.execute_input":"2024-03-18T15:26:57.893715Z","iopub.status.idle":"2024-03-18T15:26:57.904146Z","shell.execute_reply.started":"2024-03-18T15:26:57.893679Z","shell.execute_reply":"2024-03-18T15:26:57.903341Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"PROTIEN DATASET","metadata":{}},{"cell_type":"code","source":"class ProteinDataset(Dataset):\n    def __init__(self, seq_file, data_dir, label_file=None, normalize='min-max'):\n        self.seqs = pd.read_csv(seq_file)\n        \n        self.data = {}\n        for filename in os.listdir(data_dir):\n            if filename.endswith(\".csv\"):\n                protein_id = re.split(r'_train|_test', filename)[0]\n                self.data[protein_id] = pd.read_csv(os.path.join(data_dir, filename))\n        \n        if label_file:\n            self.labels = pd.read_csv(label_file)\n        else:\n            self.labels = None\n        \n        self.amino_acid_map = amino_acid_mapping\n        self.normalize_method = normalize\n        \n    def encode_sequence(self, seq):\n        encoded_seq = np.zeros((len(seq), len(self.amino_acid_map)), dtype=int)\n        for i, aa in enumerate(seq):\n            index = self.amino_acid_map.get(aa, self.amino_acid_map['X'])\n            encoded_seq[i, index] = 1\n        return encoded_seq\n    \n    def normalize_data(self, data):\n        numeric_cols = data[:, 2:]\n        data_numeric = numeric_cols.astype(np.float32)\n\n        if self.normalize_method == 'min-max':\n            min_vals = data_numeric.min(axis=0)\n            max_vals = data_numeric.max(axis=0)\n            data_range = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n            normalized_data = (data_numeric - min_vals) / data_range\n        elif self.normalize_method == 'z-score':\n            mean_vals = data_numeric.mean(axis=0)\n            std_vals = data_numeric.std(axis=0)\n            std_vals = np.where(std_vals == 0, 1, std_vals)\n            normalized_data = (data_numeric - mean_vals) / std_vals\n        else:\n            normalized_data = data_numeric\n\n        return normalized_data\n    \n    def __len__(self):\n        return len(self.seqs)\n    \n    def __getitem__(self, idx):\n        protein_id = self.seqs.iloc[idx]['PDB_ID']\n        sequence = self.seqs.iloc[idx]['SEQUENCE']\n        encoded_sequence = self.encode_sequence(sequence)\n        data = self.data[protein_id].values\n        normalized_data = self.normalize_data(data)\n\n        if self.labels is not None:\n            label_seq = self.labels.iloc[idx]['SEC_STRUCT']\n            label_numeric = [sec_struct_mapping[char] for char in label_seq]\n            label_tensor = torch.tensor(label_numeric, dtype=torch.long)\n            return (\n                protein_id,\n                torch.tensor(encoded_sequence, dtype=torch.float32),\n                torch.tensor(normalized_data, dtype=torch.float32),\n                label_tensor\n            )\n\n        return (\n            protein_id,\n            torch.tensor(encoded_sequence, dtype=torch.float32),\n            torch.tensor(normalized_data, dtype=torch.float32)\n        )","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.907466Z","iopub.execute_input":"2024-03-18T15:26:57.907775Z","iopub.status.idle":"2024-03-18T15:26:57.927009Z","shell.execute_reply.started":"2024-03-18T15:26:57.907749Z","shell.execute_reply":"2024-03-18T15:26:57.925774Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"COLLATE FUNCTION WITH AND WITHOUT LABELS","metadata":{}},{"cell_type":"code","source":"def collate_fn_no(batch):\n    ids, seqs, data = zip(*batch)\n    seqs_padded = pad_sequence([seq.clone().detach() for seq in seqs], batch_first=True)\n    data_padded = torch.tensor(data)\n    return ids, seqs_padded, data_padded\n\ndef collate_fn(batch):\n    _, seqs, data, labels = zip(*batch)\n    seqs_padded = pad_sequence([seq.clone().detach() for seq in seqs], batch_first=True)\n    data_padded = pad_sequence([d.clone().detach() for d in data], batch_first=True)\n    if labels[0] is not None:\n        labels_padded = pad_sequence([label.clone().detach() for label in labels], batch_first=True)\n    else:\n        labels_padded = None\n    \n    mask = [torch.ones(len(label), dtype=torch.uint8) for label in labels]\n    mask_padded = pad_sequence(mask, batch_first=True, padding_value=0)\n    \n    return seqs_padded, data_padded, labels_padded, mask_padded","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.928449Z","iopub.execute_input":"2024-03-18T15:26:57.928804Z","iopub.status.idle":"2024-03-18T15:26:57.943275Z","shell.execute_reply.started":"2024-03-18T15:26:57.928770Z","shell.execute_reply":"2024-03-18T15:26:57.942184Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"FULLY CONVOLUTIONAL NETWORK","metadata":{}},{"cell_type":"code","source":"class FullyConvolutionalNetwork(nn.Module):\n    def __init__(self, num_classes=3, input_channels=20):\n        super(FullyConvolutionalNetwork, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n        self.final_conv = nn.Conv1d(in_channels=256, out_channels=num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.final_conv(x)\n        x = x.transpose(1, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.945511Z","iopub.execute_input":"2024-03-18T15:26:57.945899Z","iopub.status.idle":"2024-03-18T15:26:57.955260Z","shell.execute_reply.started":"2024-03-18T15:26:57.945860Z","shell.execute_reply":"2024-03-18T15:26:57.954220Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"TRAINING MODEL","metadata":{}},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_preds = 0\n        total_preds = 0\n\n        for seqs, data, labels, _ in train_loader:\n            inputs = data.permute(0, 2, 1).to(device)\n            \n            optimizer.zero_grad()\n\n            outputs = model(inputs)\n            labels = labels.to(device)\n            loss = criterion(outputs.transpose(1, 2), labels)\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n\n            _, predicted = torch.max(outputs, 2)\n            correct_preds += (predicted == labels).sum().item()\n            total_preds += labels.numel()\n\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct_preds / total_preds\n        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.956275Z","iopub.execute_input":"2024-03-18T15:26:57.956559Z","iopub.status.idle":"2024-03-18T15:26:57.972803Z","shell.execute_reply.started":"2024-03-18T15:26:57.956534Z","shell.execute_reply":"2024-03-18T15:26:57.971589Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"VALIDATION MODEL","metadata":{}},{"cell_type":"code","source":"def validate_model(model, criterion, val_loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.eval()\n    running_loss = 0.0\n    correct_preds = 0\n    total_preds = 0\n\n    with torch.no_grad():\n        for seqs, data, labels, _ in val_loader:\n            inputs = data.permute(0, 2, 1).to(device)\n\n            outputs = model(inputs)\n            labels = labels.to(device)\n            loss = criterion(outputs.transpose(1, 2), labels)\n            running_loss += loss.item() * inputs.size(0)\n\n            _, predicted = torch.max(outputs, 2)\n            correct_preds += (predicted == labels).sum().item()\n            total_preds += labels.numel()\n\n    val_loss = running_loss / len(val_loader.dataset)\n    val_acc = correct_preds / total_preds\n    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.974547Z","iopub.execute_input":"2024-03-18T15:26:57.974982Z","iopub.status.idle":"2024-03-18T15:26:57.986056Z","shell.execute_reply.started":"2024-03-18T15:26:57.974945Z","shell.execute_reply":"2024-03-18T15:26:57.985122Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = ProteinDataset(seq_file=seqs_train_path, data_dir=train_path, label_file=labels_train_path)\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n\nmodel = FullyConvolutionalNetwork()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=0.0)\n\nnum_epochs = 10\n\ntrain_model(model, criterion, optimizer, train_loader, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:26:57.987439Z","iopub.execute_input":"2024-03-18T15:26:57.988059Z","iopub.status.idle":"2024-03-18T15:36:51.246870Z","shell.execute_reply.started":"2024-03-18T15:26:57.988027Z","shell.execute_reply":"2024-03-18T15:36:51.245618Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 0.3962, Accuracy: 0.8416\nEpoch 2/10, Loss: 0.3512, Accuracy: 0.8615\nEpoch 3/10, Loss: 0.3389, Accuracy: 0.8666\nEpoch 4/10, Loss: 0.3316, Accuracy: 0.8696\nEpoch 5/10, Loss: 0.3264, Accuracy: 0.8716\nEpoch 6/10, Loss: 0.3222, Accuracy: 0.8732\nEpoch 7/10, Loss: 0.3187, Accuracy: 0.8746\nEpoch 8/10, Loss: 0.3156, Accuracy: 0.8757\nEpoch 9/10, Loss: 0.3129, Accuracy: 0.8767\nEpoch 10/10, Loss: 0.3104, Accuracy: 0.8776\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TESTING MODEL","metadata":{}},{"cell_type":"code","source":"def test_model(model, test_dataset, output_file='submission.csv'):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n     \n        for i in range(len(test_dataset)):\n            pdb_id, _, data = test_dataset[i]\n            input_data = data.unsqueeze(0).permute(0, 2, 1).to(device)\n\n            outputs = model(input_data)\n            _, predicted = torch.max(outputs, 2)\n\n          \n            seq_len = data.shape[0]\n            for j in range(seq_len):\n                test_id = f\"{pdb_id}_{j + 1}\"\n                structure_label = ['H', 'E', 'C'][predicted[0, j].item()]\n                \n                predictions.append([test_id, structure_label])\n\n    pd.DataFrame(predictions, columns=['ID', 'STRUCTURE']).to_csv(output_file, index=False)\n    print(f'Submission file saved to {output_file}')","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:36:51.249963Z","iopub.execute_input":"2024-03-18T15:36:51.250498Z","iopub.status.idle":"2024-03-18T15:36:51.259973Z","shell.execute_reply.started":"2024-03-18T15:36:51.250468Z","shell.execute_reply":"2024-03-18T15:36:51.259032Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_dataset = ProteinDataset(seq_file=seqs_test_path, data_dir=test_path)\ntest_model(model, test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T15:36:51.261523Z","iopub.execute_input":"2024-03-18T15:36:51.261894Z","iopub.status.idle":"2024-03-18T15:36:53.736453Z","shell.execute_reply.started":"2024-03-18T15:36:51.261866Z","shell.execute_reply":"2024-03-18T15:36:53.735260Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Submission file saved to submission.csv\n","output_type":"stream"}]}]}